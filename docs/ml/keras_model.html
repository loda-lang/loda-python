<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>loda.ml.keras_model API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>loda.ml.keras_model</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from loda.lang import Program
from loda.oeis import ProgramCache
from .encoding import merge_programs, program_to_tokens, split_program, tokens_to_program

import tensorflow as tf
import os.path


class KerasModel(tf.keras.Model):

    num_ops_per_sample: int
    temperature: float
    tokens: list[str]
    vocab: list[str]

    def __init__(self, program_cache: ProgramCache, num_ops_per_sample: int = 3,
                 batch_size: int = 16, buffer_size: int = 10000,
                 embedding_dim: int = 256, num_rnn_units: int = 1024,
                 temperature: float = 1.0):
        super().__init__(self)

        # Merge all programs into one program
        merged_programs = merge_programs(program_cache, num_ops_per_sample)
        self.num_ops_per_sample = num_ops_per_sample

        # Convert to tokens and vocabulary
        self.tokens, self.vocab = program_to_tokens(merged_programs)

        # Initialize TF lookup layers
        self.tokens_to_ids = tf.keras.layers.StringLookup(
            vocabulary=list(self.vocab), mask_token=None)
        self.ids_to_tokens = tf.keras.layers.StringLookup(
            vocabulary=self.tokens_to_ids.get_vocabulary(), invert=True, mask_token=None)

        # Convert the tokens to IDs
        self.ids = self.tokens_to_ids(self.tokens)

        # === Initialize datasets ===
        self.slice_dataset = tf.data.Dataset.from_tensor_slices(self.ids)
        # One operation is encoded using three tokens
        # plus one token because we split into input/output
        self.batch_dataset = self.slice_dataset.batch(
            3 * self.num_ops_per_sample + 1, drop_remainder=True)
        self.split_dataset = self.batch_dataset.map(self.__split_input_label)
        self.prefetch_dataset = (self.split_dataset.shuffle(buffer_size).batch(
            batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))

        # === Initialize layers ===
        self.vocab_size = len(self.tokens_to_ids.get_vocabulary())
        self.embedding = tf.keras.layers.Embedding(
            self.vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(num_rnn_units,
                                       return_sequences=True,
                                       return_state=True)
        self.dense = tf.keras.layers.Dense(self.vocab_size)

        # === Initialize token generation ===
        # Create a mask to prevent &#34;[UNK]&#34; from being generated.
        self.temperature = temperature
        skip_ids = self.tokens_to_ids([&#39;[UNK]&#39;])[:, None]
        sparse_mask = tf.SparseTensor(
            # Put a -inf at each bad index.
            values=[-float(&#39;inf&#39;)]*len(skip_ids),
            indices=skip_ids,
            # Match the shape to the vocabulary
            dense_shape=[self.vocab_size])
        self.prediction_mask = tf.sparse.to_dense(sparse_mask)

    def ids_to_tokens_str(self, ids) -&gt; list[str]:
        return [t.numpy().decode(&#34;utf-8&#34;) for t in self.ids_to_tokens(ids)]

    def ids_to_programs(self, ids) -&gt; list[Program]:
        return split_program(tokens_to_program(self.ids_to_tokens_str(ids)))

    def program_to_input_ids(self, program: Program):
        tokens, _ = program_to_tokens(program)
        return tf.constant([self.tokens_to_ids(tokens).numpy()])

    def __split_input_label(self, sample: list):
        input = sample[:-1]
        label = sample[1:]
        return input, label

    def call(self, inputs, states=None, return_state=False, training=False):
        values = inputs
        values = self.embedding(values, training=training)
        if states is None:
            states = self.gru.get_initial_state(values)
        values, states = self.gru(
            values, initial_state=states, training=training)
        values = self.dense(values, training=training)
        if return_state:
            return values, states
        else:
            return values

    def fit_with_checkpoints(self, epochs: int, checkpoint_dir: str):
        checkpoint_prefix = os.path.join(checkpoint_dir, &#34;ckpt_{epoch}&#34;)
        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
            filepath=checkpoint_prefix, save_weights_only=True)
        return self.fit(self.prefetch_dataset, epochs=epochs, callbacks=[checkpoint_callback])

    def generate_id(self, inputs, states=None):

        # Run the model.
        # predicted_logits.shape is [batch, char, next_char_logits]
        predicted_logits, states = self.call(inputs=inputs, states=states,
                                             return_state=True)
        # Only use the last prediction.
        predicted_logits = predicted_logits[:, -1, :]
        predicted_logits = predicted_logits/self.temperature
        # Apply the prediction mask: prevent &#34;[UNK]&#34; from being generated.
        predicted_logits = predicted_logits + self.prediction_mask

        # Sample the output logits to generate token IDs.
        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)

        # Return the characters and model state.
        return predicted_ids, states

    def generate_token(self, inputs, states=None):
        next_id, states = self.generate_id(inputs, states=states)
        next_token = self.ids_to_tokens_str(tf.squeeze(next_id, axis=-1))[0]
        return next_id, next_token, states</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="loda.ml.keras_model.KerasModel"><code class="flex name class">
<span>class <span class="ident">KerasModel</span></span>
<span>(</span><span>program_cache: <a title="loda.oeis.program_cache.ProgramCache" href="../oeis/program_cache.html#loda.oeis.program_cache.ProgramCache">ProgramCache</a>, num_ops_per_sample: int = 3, batch_size: int = 16, buffer_size: int = 10000, embedding_dim: int = 256, num_rnn_units: int = 1024, temperature: float = 1.0)</span>
</code></dt>
<dd>
<div class="desc"><p><code>Model</code> groups layers into an object with training and inference features.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inputs</code></strong></dt>
<dd>The input(s) of the model: a <code>keras.Input</code> object or a
combination of <code>keras.Input</code> objects in a dict, list or tuple.</dd>
<dt><strong><code>outputs</code></strong></dt>
<dd>The output(s) of the model: a tensor that originated from
<code>keras.Input</code> objects or a combination of such tensors in a dict,
list or tuple. See Functional API example below.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>String, the name of the model.</dd>
</dl>
<p>There are two ways to instantiate a <code>Model</code>:</p>
<p>1 - With the "Functional API", where you start from <code>Input</code>,
you chain layer calls to specify the model's forward pass,
and finally you create your model from inputs and outputs:</p>
<pre><code class="language-python">import tensorflow as tf

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
</code></pre>
<p>Note: Only dicts, lists, and tuples of input tensors are supported. Nested
inputs are not supported (e.g. lists of list or dicts of dict).</p>
<p>A new Functional API model can also be created by using the
intermediate tensors. This enables you to quickly extract sub-components
of the model.</p>
<p>Example:</p>
<pre><code class="language-python">inputs = keras.Input(shape=(None, None, 3))
processed = keras.layers.RandomCrop(width=32, height=32)(inputs)
conv = keras.layers.Conv2D(filters=2, kernel_size=3)(processed)
pooling = keras.layers.GlobalAveragePooling2D()(conv)
feature = keras.layers.Dense(10)(pooling)

full_model = keras.Model(inputs, feature)
backbone = keras.Model(processed, conv)
activations = keras.Model(conv, feature)
</code></pre>
<p>Note that the <code>backbone</code> and <code>activations</code> models are not
created with <code>keras.Input</code> objects, but with the tensors that are originated
from <code>keras.Input</code> objects. Under the hood, the layers and weights will
be shared across these models, so that user can train the <code>full_model</code>, and
use <code>backbone</code> or <code>activations</code> to do feature extraction.
The inputs and outputs of the model can be nested structures of tensors as
well, and the created models are standard Functional API models that support
all the existing APIs.</p>
<p>2 - By subclassing the <code>Model</code> class: in that case, you should define your
layers in <code>__init__()</code> and you should implement the model's forward pass
in <code>call()</code>.</p>
<pre><code class="language-python">import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super().__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)

  def call(self, inputs):
    x = self.dense1(inputs)
    return self.dense2(x)

model = MyModel()
</code></pre>
<p>If you subclass <code>Model</code>, you can optionally have
a <code>training</code> argument (boolean) in <code>call()</code>, which you can use to specify
a different behavior in training and inference:</p>
<pre><code class="language-python">import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super().__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
    self.dropout = tf.keras.layers.Dropout(0.5)

  def call(self, inputs, training=False):
    x = self.dense1(inputs)
    if training:
      x = self.dropout(x, training=training)
    return self.dense2(x)

model = MyModel()
</code></pre>
<p>Once the model is created, you can config the model with losses and metrics
with <code>model.compile()</code>, train the model with <code>model.fit()</code>, or use the model
to do prediction with <code>model.predict()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KerasModel(tf.keras.Model):

    num_ops_per_sample: int
    temperature: float
    tokens: list[str]
    vocab: list[str]

    def __init__(self, program_cache: ProgramCache, num_ops_per_sample: int = 3,
                 batch_size: int = 16, buffer_size: int = 10000,
                 embedding_dim: int = 256, num_rnn_units: int = 1024,
                 temperature: float = 1.0):
        super().__init__(self)

        # Merge all programs into one program
        merged_programs = merge_programs(program_cache, num_ops_per_sample)
        self.num_ops_per_sample = num_ops_per_sample

        # Convert to tokens and vocabulary
        self.tokens, self.vocab = program_to_tokens(merged_programs)

        # Initialize TF lookup layers
        self.tokens_to_ids = tf.keras.layers.StringLookup(
            vocabulary=list(self.vocab), mask_token=None)
        self.ids_to_tokens = tf.keras.layers.StringLookup(
            vocabulary=self.tokens_to_ids.get_vocabulary(), invert=True, mask_token=None)

        # Convert the tokens to IDs
        self.ids = self.tokens_to_ids(self.tokens)

        # === Initialize datasets ===
        self.slice_dataset = tf.data.Dataset.from_tensor_slices(self.ids)
        # One operation is encoded using three tokens
        # plus one token because we split into input/output
        self.batch_dataset = self.slice_dataset.batch(
            3 * self.num_ops_per_sample + 1, drop_remainder=True)
        self.split_dataset = self.batch_dataset.map(self.__split_input_label)
        self.prefetch_dataset = (self.split_dataset.shuffle(buffer_size).batch(
            batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))

        # === Initialize layers ===
        self.vocab_size = len(self.tokens_to_ids.get_vocabulary())
        self.embedding = tf.keras.layers.Embedding(
            self.vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(num_rnn_units,
                                       return_sequences=True,
                                       return_state=True)
        self.dense = tf.keras.layers.Dense(self.vocab_size)

        # === Initialize token generation ===
        # Create a mask to prevent &#34;[UNK]&#34; from being generated.
        self.temperature = temperature
        skip_ids = self.tokens_to_ids([&#39;[UNK]&#39;])[:, None]
        sparse_mask = tf.SparseTensor(
            # Put a -inf at each bad index.
            values=[-float(&#39;inf&#39;)]*len(skip_ids),
            indices=skip_ids,
            # Match the shape to the vocabulary
            dense_shape=[self.vocab_size])
        self.prediction_mask = tf.sparse.to_dense(sparse_mask)

    def ids_to_tokens_str(self, ids) -&gt; list[str]:
        return [t.numpy().decode(&#34;utf-8&#34;) for t in self.ids_to_tokens(ids)]

    def ids_to_programs(self, ids) -&gt; list[Program]:
        return split_program(tokens_to_program(self.ids_to_tokens_str(ids)))

    def program_to_input_ids(self, program: Program):
        tokens, _ = program_to_tokens(program)
        return tf.constant([self.tokens_to_ids(tokens).numpy()])

    def __split_input_label(self, sample: list):
        input = sample[:-1]
        label = sample[1:]
        return input, label

    def call(self, inputs, states=None, return_state=False, training=False):
        values = inputs
        values = self.embedding(values, training=training)
        if states is None:
            states = self.gru.get_initial_state(values)
        values, states = self.gru(
            values, initial_state=states, training=training)
        values = self.dense(values, training=training)
        if return_state:
            return values, states
        else:
            return values

    def fit_with_checkpoints(self, epochs: int, checkpoint_dir: str):
        checkpoint_prefix = os.path.join(checkpoint_dir, &#34;ckpt_{epoch}&#34;)
        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
            filepath=checkpoint_prefix, save_weights_only=True)
        return self.fit(self.prefetch_dataset, epochs=epochs, callbacks=[checkpoint_callback])

    def generate_id(self, inputs, states=None):

        # Run the model.
        # predicted_logits.shape is [batch, char, next_char_logits]
        predicted_logits, states = self.call(inputs=inputs, states=states,
                                             return_state=True)
        # Only use the last prediction.
        predicted_logits = predicted_logits[:, -1, :]
        predicted_logits = predicted_logits/self.temperature
        # Apply the prediction mask: prevent &#34;[UNK]&#34; from being generated.
        predicted_logits = predicted_logits + self.prediction_mask

        # Sample the output logits to generate token IDs.
        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)

        # Return the characters and model state.
        return predicted_ids, states

    def generate_token(self, inputs, states=None):
        next_id, states = self.generate_id(inputs, states=states)
        next_token = self.ids_to_tokens_str(tf.squeeze(next_id, axis=-1))[0]
        return next_id, next_token, states</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.engine.training.Model</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
<li>keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="loda.ml.keras_model.KerasModel.num_ops_per_sample"><code class="name">var <span class="ident">num_ops_per_sample</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="loda.ml.keras_model.KerasModel.temperature"><code class="name">var <span class="ident">temperature</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="loda.ml.keras_model.KerasModel.tokens"><code class="name">var <span class="ident">tokens</span> : list[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="loda.ml.keras_model.KerasModel.vocab"><code class="name">var <span class="ident">vocab</span> : list[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="loda.ml.keras_model.KerasModel.call"><code class="name flex">
<span>def <span class="ident">call</span></span>(<span>self, inputs, states=None, return_state=False, training=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls the model on new inputs and returns the outputs as tensors.</p>
<p>In this case <code>call()</code> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<p>Note: This method should not be called directly. It is only meant to be
overridden when subclassing <code>tf.keras.Model</code>.
To call a model on an input, always use the <code>__call__()</code> method,
i.e. <code>model(inputs)</code>, which relies on the underlying <code>call()</code> method.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inputs</code></strong></dt>
<dd>Input tensor, or dict/list/tuple of input tensors.</dd>
<dt><strong><code>training</code></strong></dt>
<dd>Boolean or boolean scalar tensor, indicating whether to
run the <code>Network</code> in training mode or inference mode.</dd>
<dt><strong><code>mask</code></strong></dt>
<dd>A mask or list of masks. A mask can be either a boolean tensor
or None (no mask). For more details, check the guide
<a href="https://www.tensorflow.org/guide/keras/masking_and_padding">here</a>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def call(self, inputs, states=None, return_state=False, training=False):
    values = inputs
    values = self.embedding(values, training=training)
    if states is None:
        states = self.gru.get_initial_state(values)
    values, states = self.gru(
        values, initial_state=states, training=training)
    values = self.dense(values, training=training)
    if return_state:
        return values, states
    else:
        return values</code></pre>
</details>
</dd>
<dt id="loda.ml.keras_model.KerasModel.fit_with_checkpoints"><code class="name flex">
<span>def <span class="ident">fit_with_checkpoints</span></span>(<span>self, epochs: int, checkpoint_dir: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_with_checkpoints(self, epochs: int, checkpoint_dir: str):
    checkpoint_prefix = os.path.join(checkpoint_dir, &#34;ckpt_{epoch}&#34;)
    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_prefix, save_weights_only=True)
    return self.fit(self.prefetch_dataset, epochs=epochs, callbacks=[checkpoint_callback])</code></pre>
</details>
</dd>
<dt id="loda.ml.keras_model.KerasModel.generate_id"><code class="name flex">
<span>def <span class="ident">generate_id</span></span>(<span>self, inputs, states=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_id(self, inputs, states=None):

    # Run the model.
    # predicted_logits.shape is [batch, char, next_char_logits]
    predicted_logits, states = self.call(inputs=inputs, states=states,
                                         return_state=True)
    # Only use the last prediction.
    predicted_logits = predicted_logits[:, -1, :]
    predicted_logits = predicted_logits/self.temperature
    # Apply the prediction mask: prevent &#34;[UNK]&#34; from being generated.
    predicted_logits = predicted_logits + self.prediction_mask

    # Sample the output logits to generate token IDs.
    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)

    # Return the characters and model state.
    return predicted_ids, states</code></pre>
</details>
</dd>
<dt id="loda.ml.keras_model.KerasModel.generate_token"><code class="name flex">
<span>def <span class="ident">generate_token</span></span>(<span>self, inputs, states=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_token(self, inputs, states=None):
    next_id, states = self.generate_id(inputs, states=states)
    next_token = self.ids_to_tokens_str(tf.squeeze(next_id, axis=-1))[0]
    return next_id, next_token, states</code></pre>
</details>
</dd>
<dt id="loda.ml.keras_model.KerasModel.ids_to_programs"><code class="name flex">
<span>def <span class="ident">ids_to_programs</span></span>(<span>self, ids) ‑> list[<a title="loda.lang.program.Program" href="../lang/program.html#loda.lang.program.Program">Program</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ids_to_programs(self, ids) -&gt; list[Program]:
    return split_program(tokens_to_program(self.ids_to_tokens_str(ids)))</code></pre>
</details>
</dd>
<dt id="loda.ml.keras_model.KerasModel.ids_to_tokens_str"><code class="name flex">
<span>def <span class="ident">ids_to_tokens_str</span></span>(<span>self, ids) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ids_to_tokens_str(self, ids) -&gt; list[str]:
    return [t.numpy().decode(&#34;utf-8&#34;) for t in self.ids_to_tokens(ids)]</code></pre>
</details>
</dd>
<dt id="loda.ml.keras_model.KerasModel.program_to_input_ids"><code class="name flex">
<span>def <span class="ident">program_to_input_ids</span></span>(<span>self, program: <a title="loda.lang.program.Program" href="../lang/program.html#loda.lang.program.Program">Program</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def program_to_input_ids(self, program: Program):
    tokens, _ = program_to_tokens(program)
    return tf.constant([self.tokens_to_ids(tokens).numpy()])</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="loda.ml" href="index.html">loda.ml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="loda.ml.keras_model.KerasModel" href="#loda.ml.keras_model.KerasModel">KerasModel</a></code></h4>
<ul class="">
<li><code><a title="loda.ml.keras_model.KerasModel.call" href="#loda.ml.keras_model.KerasModel.call">call</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.fit_with_checkpoints" href="#loda.ml.keras_model.KerasModel.fit_with_checkpoints">fit_with_checkpoints</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.generate_id" href="#loda.ml.keras_model.KerasModel.generate_id">generate_id</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.generate_token" href="#loda.ml.keras_model.KerasModel.generate_token">generate_token</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.ids_to_programs" href="#loda.ml.keras_model.KerasModel.ids_to_programs">ids_to_programs</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.ids_to_tokens_str" href="#loda.ml.keras_model.KerasModel.ids_to_tokens_str">ids_to_tokens_str</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.num_ops_per_sample" href="#loda.ml.keras_model.KerasModel.num_ops_per_sample">num_ops_per_sample</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.program_to_input_ids" href="#loda.ml.keras_model.KerasModel.program_to_input_ids">program_to_input_ids</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.temperature" href="#loda.ml.keras_model.KerasModel.temperature">temperature</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.tokens" href="#loda.ml.keras_model.KerasModel.tokens">tokens</a></code></li>
<li><code><a title="loda.ml.keras_model.KerasModel.vocab" href="#loda.ml.keras_model.KerasModel.vocab">vocab</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>